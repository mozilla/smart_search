{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d9ac78b-577d-4df3-ba83-2772e72aa44e",
   "metadata": {},
   "source": [
    "Purpose of this notebook is to explore the semantic search use case with browsing history in mind\n",
    "- Important caveat is to explore the support for multiple languges\n",
    "\n",
    "Reference link -> https://data.firefox.com/dashboard/usage-behavior\n",
    "\n",
    "  Worldwide, English (US) remains the most common, at about 40% of the population, with German (11%) and French (8.1%) coming 2nd and 3rd. Simplified Chinese is the 4th most common language (6.7%), and Spanish (Spain) is the 5th most common language (5%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75ed6f87-125e-4b61-8038-1447fe5fefb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import onnxruntime as ort\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df6bb164-1bed-4b58-96c9-19e7070c2037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the project root directory to the Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "082f0f21-7a18-4e17-a9e5-36571b06679f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.constants import EMBEDDING_MODELS_DICT\n",
    "from src.feature_extractor import FeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fd90da7-afc6-4c89-bf4e-057cd29e7ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp /tmp/output_file.txt /Users/cgopal/Downloads/places_output_file_v1.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f926249d-62f9-4d50-a40a-9b3599122b4e",
   "metadata": {},
   "source": [
    "#### Lets try reading browsing history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0e403e-5e3e-4fbd-af8a-41a9a9783231",
   "metadata": {},
   "source": [
    "Download browsing history:\n",
    "\n",
    "1) cp \"/Users/<username>/Library/Application Support/Firefox/Profiles/<profilename>/places.sqlite\" /tmp/places.sqlite\n",
    "2) sqlite3 /tmp/places.sqlite\n",
    "3) within sqlite run below commands one by one\n",
    "```\n",
    ".schema moz_places\n",
    ".mode list\n",
    ".separator \"~|\"\n",
    ".output output_file_v2.txt\n",
    "SELECT url, title, description, preview_image_url, frecency, last_visit_date FROM moz_places\n",
    "WHERE description  NOTNULL\n",
    "ORDER BY last_visit_date DESC limit 600\n",
    "```\n",
    "4) copy the file output_file_v2 to ~/Downloads/places_output_file_v2.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2eaa29f-ff0f-453f-af8e-e82aab89c051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "671\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>url</th>\n",
       "      <td>https://huggingface.co/Xenova/LaBSE/tree/main</td>\n",
       "      <td>https://huggingface.co/Xenova/LaBSE/blob/main/...</td>\n",
       "      <td>https://huggingface.co/Xenova/LaBSE/tree/main/...</td>\n",
       "      <td>https://huggingface.co/Xenova/LaBSE</td>\n",
       "      <td>https://huggingface.co/models?other=base_model...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>Xenova/LaBSE at main</td>\n",
       "      <td>onnx/model_quantized.onnx · Xenova/LaBSE at main</td>\n",
       "      <td>Xenova/LaBSE at main</td>\n",
       "      <td>Xenova/LaBSE · Hugging Face</td>\n",
       "      <td>Models - Hugging Face</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>We’re on a journey to advance and democratize ...</td>\n",
       "      <td>We’re on a journey to advance and democratize ...</td>\n",
       "      <td>We’re on a journey to advance and democratize ...</td>\n",
       "      <td>We’re on a journey to advance and democratize ...</td>\n",
       "      <td>We’re on a journey to advance and democratize ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preview_image_url</th>\n",
       "      <td>https://cdn-thumbnails.huggingface.co/social-t...</td>\n",
       "      <td>https://cdn-thumbnails.huggingface.co/social-t...</td>\n",
       "      <td>https://cdn-thumbnails.huggingface.co/social-t...</td>\n",
       "      <td>https://cdn-thumbnails.huggingface.co/social-t...</td>\n",
       "      <td>https://cdn-thumbnails.huggingface.co/social-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frecency</th>\n",
       "      <td>200.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_visit_date</th>\n",
       "      <td>1733944720780624.0</td>\n",
       "      <td>1733944695474407.0</td>\n",
       "      <td>1733944640389418.0</td>\n",
       "      <td>1733944636441166.0</td>\n",
       "      <td>1733944631579349.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   0  \\\n",
       "url                    https://huggingface.co/Xenova/LaBSE/tree/main   \n",
       "title                                           Xenova/LaBSE at main   \n",
       "description        We’re on a journey to advance and democratize ...   \n",
       "preview_image_url  https://cdn-thumbnails.huggingface.co/social-t...   \n",
       "frecency                                                       200.0   \n",
       "last_visit_date                                   1733944720780624.0   \n",
       "\n",
       "                                                                   1  \\\n",
       "url                https://huggingface.co/Xenova/LaBSE/blob/main/...   \n",
       "title               onnx/model_quantized.onnx · Xenova/LaBSE at main   \n",
       "description        We’re on a journey to advance and democratize ...   \n",
       "preview_image_url  https://cdn-thumbnails.huggingface.co/social-t...   \n",
       "frecency                                                       100.0   \n",
       "last_visit_date                                   1733944695474407.0   \n",
       "\n",
       "                                                                   2  \\\n",
       "url                https://huggingface.co/Xenova/LaBSE/tree/main/...   \n",
       "title                                           Xenova/LaBSE at main   \n",
       "description        We’re on a journey to advance and democratize ...   \n",
       "preview_image_url  https://cdn-thumbnails.huggingface.co/social-t...   \n",
       "frecency                                                       100.0   \n",
       "last_visit_date                                   1733944640389418.0   \n",
       "\n",
       "                                                                   3  \\\n",
       "url                              https://huggingface.co/Xenova/LaBSE   \n",
       "title                                    Xenova/LaBSE · Hugging Face   \n",
       "description        We’re on a journey to advance and democratize ...   \n",
       "preview_image_url  https://cdn-thumbnails.huggingface.co/social-t...   \n",
       "frecency                                                       100.0   \n",
       "last_visit_date                                   1733944636441166.0   \n",
       "\n",
       "                                                                   4  \n",
       "url                https://huggingface.co/models?other=base_model...  \n",
       "title                                          Models - Hugging Face  \n",
       "description        We’re on a journey to advance and democratize ...  \n",
       "preview_image_url  https://cdn-thumbnails.huggingface.co/social-t...  \n",
       "frecency                                                       100.0  \n",
       "last_visit_date                                   1733944631579349.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = pd.read_csv(\"/Users/cgopal/Downloads/places_output_file_v2.txt\",\n",
    "                      sep=\"~\\\\|\", engine=\"python\", header=None, encoding=\"utf-8\", on_bad_lines=\"skip\", index_col=False,\n",
    "                      names=['url', 'title', 'description', 'preview_image_url', 'frecency', 'last_visit_date'])\n",
    "\n",
    "print(len(history))\n",
    "history.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "201d017d-9ddb-4674-81f0-b1f83710061d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history['last_visit_date'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "358f5a7d-6353-4ac8-bb44-a2ede8a7084a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "671\n"
     ]
    }
   ],
   "source": [
    "history['last_visit_date'] = pd.to_datetime(history['last_visit_date'], unit='us')\n",
    "\n",
    "# fill empty last_visit_date with default value \"1970-01-01\"\n",
    "history['last_visit_date'] = history['last_visit_date'].fillna(pd.to_datetime(\"1970-01-01\"))\n",
    "history['combined_text'] = history['title'].fillna('') + \" \" + history['description'].fillna('')\n",
    "history = history.loc[history['combined_text'] != ''].reset_index(drop=True)\n",
    "\n",
    "print(len(history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "001c3a82-ea77-4dac-af08-0c7a7ccb6bec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>preview_image_url</th>\n",
       "      <th>frecency</th>\n",
       "      <th>last_visit_date</th>\n",
       "      <th>combined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://huggingface.co/Xenova/LaBSE/tree/main</td>\n",
       "      <td>Xenova/LaBSE at main</td>\n",
       "      <td>We’re on a journey to advance and democratize ...</td>\n",
       "      <td>https://cdn-thumbnails.huggingface.co/social-t...</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2024-12-11 19:18:40.780624</td>\n",
       "      <td>Xenova/LaBSE at main We’re on a journey to adv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://huggingface.co/Xenova/LaBSE/blob/main/...</td>\n",
       "      <td>onnx/model_quantized.onnx · Xenova/LaBSE at main</td>\n",
       "      <td>We’re on a journey to advance and democratize ...</td>\n",
       "      <td>https://cdn-thumbnails.huggingface.co/social-t...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2024-12-11 19:18:15.474407</td>\n",
       "      <td>onnx/model_quantized.onnx · Xenova/LaBSE at ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://huggingface.co/Xenova/LaBSE/tree/main/...</td>\n",
       "      <td>Xenova/LaBSE at main</td>\n",
       "      <td>We’re on a journey to advance and democratize ...</td>\n",
       "      <td>https://cdn-thumbnails.huggingface.co/social-t...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2024-12-11 19:17:20.389418</td>\n",
       "      <td>Xenova/LaBSE at main We’re on a journey to adv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://huggingface.co/Xenova/LaBSE</td>\n",
       "      <td>Xenova/LaBSE · Hugging Face</td>\n",
       "      <td>We’re on a journey to advance and democratize ...</td>\n",
       "      <td>https://cdn-thumbnails.huggingface.co/social-t...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2024-12-11 19:17:16.441166</td>\n",
       "      <td>Xenova/LaBSE · Hugging Face We’re on a journey...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://huggingface.co/models?other=base_model...</td>\n",
       "      <td>Models - Hugging Face</td>\n",
       "      <td>We’re on a journey to advance and democratize ...</td>\n",
       "      <td>https://cdn-thumbnails.huggingface.co/social-t...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2024-12-11 19:17:11.579349</td>\n",
       "      <td>Models - Hugging Face We’re on a journey to ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>https://source.coop/repositories/fused/fsq-os-...</td>\n",
       "      <td>Source Cooperative</td>\n",
       "      <td>Source Cooperative is a neutral, non-profit da...</td>\n",
       "      <td>https://source.coop/repositories/fused/fsq-os-...</td>\n",
       "      <td>258.0</td>\n",
       "      <td>2024-11-27 16:55:08.667714</td>\n",
       "      <td>Source Cooperative Source Cooperative is a neu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>https://huggingface.co/docs/transformers/en/mo...</td>\n",
       "      <td>Summary of the tokenizers</td>\n",
       "      <td>We’re on a journey to advance and democratize ...</td>\n",
       "      <td>https://huggingface.co/front/thumbnails/docs/t...</td>\n",
       "      <td>172.0</td>\n",
       "      <td>2024-11-27 14:34:40.388465</td>\n",
       "      <td>Summary of the tokenizers We’re on a journey t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>https://pernos.co/</td>\n",
       "      <td>Pernosco</td>\n",
       "      <td>Fast, fun, omniscient debugging. Record failur...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>172.0</td>\n",
       "      <td>2024-11-27 13:17:17.232790</td>\n",
       "      <td>Pernosco Fast, fun, omniscient debugging. Reco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>https://mozilla.zoom.us/j/96967081587?pwd=Plcw...</td>\n",
       "      <td>Launch Meeting - Zoom</td>\n",
       "      <td>Zoom is the leader in modern enterprise video ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2024-11-27 13:05:19.391346</td>\n",
       "      <td>Launch Meeting - Zoom Zoom is the leader in mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>https://github.com/google-research/bert/blob/m...</td>\n",
       "      <td>bert/tokenization.py at master · google-resear...</td>\n",
       "      <td>TensorFlow code and pre-trained models for BER...</td>\n",
       "      <td>https://opengraph.githubassets.com/744738b05ca...</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2024-11-27 13:03:26.064143</td>\n",
       "      <td>bert/tokenization.py at master · google-resear...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>671 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   url  \\\n",
       "0        https://huggingface.co/Xenova/LaBSE/tree/main   \n",
       "1    https://huggingface.co/Xenova/LaBSE/blob/main/...   \n",
       "2    https://huggingface.co/Xenova/LaBSE/tree/main/...   \n",
       "3                  https://huggingface.co/Xenova/LaBSE   \n",
       "4    https://huggingface.co/models?other=base_model...   \n",
       "..                                                 ...   \n",
       "666  https://source.coop/repositories/fused/fsq-os-...   \n",
       "667  https://huggingface.co/docs/transformers/en/mo...   \n",
       "668                                 https://pernos.co/   \n",
       "669  https://mozilla.zoom.us/j/96967081587?pwd=Plcw...   \n",
       "670  https://github.com/google-research/bert/blob/m...   \n",
       "\n",
       "                                                 title  \\\n",
       "0                                 Xenova/LaBSE at main   \n",
       "1     onnx/model_quantized.onnx · Xenova/LaBSE at main   \n",
       "2                                 Xenova/LaBSE at main   \n",
       "3                          Xenova/LaBSE · Hugging Face   \n",
       "4                                Models - Hugging Face   \n",
       "..                                                 ...   \n",
       "666                                 Source Cooperative   \n",
       "667                          Summary of the tokenizers   \n",
       "668                                           Pernosco   \n",
       "669                              Launch Meeting - Zoom   \n",
       "670  bert/tokenization.py at master · google-resear...   \n",
       "\n",
       "                                           description  \\\n",
       "0    We’re on a journey to advance and democratize ...   \n",
       "1    We’re on a journey to advance and democratize ...   \n",
       "2    We’re on a journey to advance and democratize ...   \n",
       "3    We’re on a journey to advance and democratize ...   \n",
       "4    We’re on a journey to advance and democratize ...   \n",
       "..                                                 ...   \n",
       "666  Source Cooperative is a neutral, non-profit da...   \n",
       "667  We’re on a journey to advance and democratize ...   \n",
       "668  Fast, fun, omniscient debugging. Record failur...   \n",
       "669  Zoom is the leader in modern enterprise video ...   \n",
       "670  TensorFlow code and pre-trained models for BER...   \n",
       "\n",
       "                                     preview_image_url  frecency  \\\n",
       "0    https://cdn-thumbnails.huggingface.co/social-t...     200.0   \n",
       "1    https://cdn-thumbnails.huggingface.co/social-t...     100.0   \n",
       "2    https://cdn-thumbnails.huggingface.co/social-t...     100.0   \n",
       "3    https://cdn-thumbnails.huggingface.co/social-t...     100.0   \n",
       "4    https://cdn-thumbnails.huggingface.co/social-t...     100.0   \n",
       "..                                                 ...       ...   \n",
       "666  https://source.coop/repositories/fused/fsq-os-...     258.0   \n",
       "667  https://huggingface.co/front/thumbnails/docs/t...     172.0   \n",
       "668                                                NaN     172.0   \n",
       "669                                                NaN      88.0   \n",
       "670  https://opengraph.githubassets.com/744738b05ca...      88.0   \n",
       "\n",
       "               last_visit_date  \\\n",
       "0   2024-12-11 19:18:40.780624   \n",
       "1   2024-12-11 19:18:15.474407   \n",
       "2   2024-12-11 19:17:20.389418   \n",
       "3   2024-12-11 19:17:16.441166   \n",
       "4   2024-12-11 19:17:11.579349   \n",
       "..                         ...   \n",
       "666 2024-11-27 16:55:08.667714   \n",
       "667 2024-11-27 14:34:40.388465   \n",
       "668 2024-11-27 13:17:17.232790   \n",
       "669 2024-11-27 13:05:19.391346   \n",
       "670 2024-11-27 13:03:26.064143   \n",
       "\n",
       "                                         combined_text  \n",
       "0    Xenova/LaBSE at main We’re on a journey to adv...  \n",
       "1    onnx/model_quantized.onnx · Xenova/LaBSE at ma...  \n",
       "2    Xenova/LaBSE at main We’re on a journey to adv...  \n",
       "3    Xenova/LaBSE · Hugging Face We’re on a journey...  \n",
       "4    Models - Hugging Face We’re on a journey to ad...  \n",
       "..                                                 ...  \n",
       "666  Source Cooperative Source Cooperative is a neu...  \n",
       "667  Summary of the tokenizers We’re on a journey t...  \n",
       "668  Pernosco Fast, fun, omniscient debugging. Reco...  \n",
       "669  Launch Meeting - Zoom Zoom is the leader in mo...  \n",
       "670  bert/tokenization.py at master · google-resear...  \n",
       "\n",
       "[671 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8484e2cc-b101-44ff-87b0-1f7b5f5ac732",
   "metadata": {},
   "source": [
    "#### find appropriate max token length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71b131ae-6bfb-4dbc-893f-5dff571e2c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.8\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fe80a99-d54c-40fb-bbd1-4ba72a78c9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install tiktoken\n",
    "# !python -m pip freeze| grep tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4ccdbf2-582a-4d43-9b85-af8926ed1f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tiktoken.list_encoding_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3495f161-de13-4fff-b9e1-e6bda4d0c3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum token count: 110\n",
      "95th percentile token count: 78.0\n",
      "99th percentile token count: 100.29999999999995\n"
     ]
    }
   ],
   "source": [
    "# # import pandas as pd\n",
    "# import tiktoken\n",
    "# # import numpy as np\n",
    "\n",
    "# # Sample data\n",
    "# # history\n",
    "\n",
    "# # Initialize the tokenizer\n",
    "# # Replace 'gpt-3.5-turbo' with the model/tokenizer you want to use\n",
    "# tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "# # Tokenize each text and count tokens\n",
    "# history['token_count'] = history['combined_text'].apply(lambda x: len(tokenizer.encode(x)))\n",
    "\n",
    "# # Compute statistics\n",
    "# max_length = history['token_count'].max()\n",
    "# percentile_95 = np.percentile(history['token_count'], 95)\n",
    "# percentile_99 = np.percentile(history['token_count'], 99)\n",
    "\n",
    "# print(f\"Maximum token count: {max_length}\")\n",
    "# print(f\"95th percentile token count: {percentile_95}\")\n",
    "# print(f\"99th percentile token count: {percentile_99}\")\n",
    "\n",
    "# # Decide on an appropriate max_length based on these statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5976192a-a663-4ad7-b5e5-f795abb30c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2295900-4902-4f6c-b1af-0dd391f46037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Xenova/all-MiniLM-L6-v2': 'https://huggingface.co/Xenova/all-MiniLM-L6-v2/resolve/main/onnx/model_quantized.onnx',\n",
       " 'nomic-ai/nomic-embed-text-v1.5': 'https://huggingface.co/nomic-ai/nomic-embed-text-v1.5/resolve/main/onnx/model_quantized.onnx',\n",
       " 'Xenova/all-mpnet-base-v2': 'https://huggingface.co/Xenova/all-mpnet-base-v2/resolve/main/onnx/model_quantized.onnx',\n",
       " 'Xenova/paraphrase-mpnet-base-v2': 'https://huggingface.co/Xenova/paraphrase-mpnet-base-v2/resolve/main/onnx/model_quantized.onnx',\n",
       " 'Xenova/all-MiniLM-L12-v2': 'https://huggingface.co/Xenova/all-MiniLM-L12-v2/resolve/main/onnx/model_quantized.onnx',\n",
       " 'nomic-ai/modernbert-embed-base': 'https://huggingface.co/nomic-ai/modernbert-embed-base/resolve/main/onnx/model_quantized.onnx'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMBEDDING_MODELS_DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64da1867-5f42-49cd-adc9-d60a5cc1e6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected model is Xenova/all-MiniLM-L6-v2\n",
      "Xenova/all-MiniLM-L6-v2 (671, 384)\n",
      "selected model is nomic-ai/nomic-embed-text-v1.5\n",
      "nomic-ai/nomic-embed-text-v1.5 (671, 768)\n",
      "selected model is Xenova/all-mpnet-base-v2\n",
      "Xenova/all-mpnet-base-v2 (671, 768)\n",
      "selected model is Xenova/paraphrase-mpnet-base-v2\n",
      "Xenova/paraphrase-mpnet-base-v2 (671, 768)\n",
      "selected model is Xenova/all-MiniLM-L12-v2\n",
      "Xenova/all-MiniLM-L12-v2 (671, 384)\n",
      "selected model is nomic-ai/modernbert-embed-base\n",
      "nomic-ai/modernbert-embed-base (671, 768)\n"
     ]
    }
   ],
   "source": [
    "texts = history['combined_text'].values.tolist()\n",
    "embeddings_dict = {}\n",
    "embeddings_sizes = {}\n",
    "\n",
    "for model in EMBEDDING_MODELS_DICT.keys():\n",
    "    fe = FeatureExtractor(EMBEDDING_MODELS_DICT, model_name=model)\n",
    "    embeddings_dict[model] = fe.get_embeddings(texts)\n",
    "    print(model, embeddings_dict[model].shape)\n",
    "    embeddings_sizes[model] = embeddings_dict[model].shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6ecf32f-af2a-4fe5-bb3e-d1a0f0d39e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Xenova/all-MiniLM-L6-v2': 384,\n",
       " 'nomic-ai/nomic-embed-text-v1.5': 768,\n",
       " 'Xenova/all-mpnet-base-v2': 768,\n",
       " 'Xenova/paraphrase-mpnet-base-v2': 768,\n",
       " 'Xenova/all-MiniLM-L12-v2': 384,\n",
       " 'nomic-ai/modernbert-embed-base': 768}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62f4f1e5-fd70-4ec9-9644-c6f68b577b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Xenova/all-MiniLM-L6-v2', 'nomic-ai/nomic-embed-text-v1.5', 'Xenova/all-mpnet-base-v2', 'Xenova/paraphrase-mpnet-base-v2', 'Xenova/all-MiniLM-L12-v2', 'nomic-ai/modernbert-embed-base'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbae0da7-da91-413d-9da4-db3cbefb42af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(671, 768)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dict['nomic-ai/modernbert-embed-base'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "055a6158-d681-4aa6-b66c-b4c1eb4d0e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings_dict['answerdotai/ModernBERT-base'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0043dcc0-8373-4288-8b0c-3df00546dc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df588b4d-61d4-4e30-9cb9-001cb9747ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../data/embeddings_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(embeddings_dict, f)\n",
    "\n",
    "with open(\"../data/embeddings_sizes.pkl\", \"wb\") as f:\n",
    "    pickle.dump(embeddings_sizes, f)\n",
    "\n",
    "history.to_csv(\"../data/history.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61265f7e-aff7-4893-b3c8-9a8c1b666738",
   "metadata": {},
   "source": [
    "#### Explore sqlite vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "80ed6d29-8887-4b10-b21d-3a02b1b78362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sqlite3\n",
    "import sqlite_vec\n",
    "\n",
    "from typing import List\n",
    "import struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9836b48c-77ed-40d3-b0df-a542df31630d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def serialize_f32(vector: List[float]) -> bytes:\n",
    "    \"\"\"serializes a list of floats into a compact \"raw bytes\" format\"\"\"\n",
    "    return struct.pack(\"%sf\" % len(vector), *vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "012041ff-936b-4163-bc21-fa34012f7b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite_version=3.47.2, vec_version=v0.1.6\n"
     ]
    }
   ],
   "source": [
    "db = sqlite3.connect(\":memory:\")\n",
    "db.enable_load_extension(True)\n",
    "sqlite_vec.load(db)\n",
    "db.enable_load_extension(False)\n",
    "\n",
    "sqlite_version, vec_version = db.execute(\n",
    "    \"select sqlite_version(), vec_version()\"\n",
    ").fetchone()\n",
    "print(f\"sqlite_version={sqlite_version}, vec_version={vec_version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "572d7447-4cd5-4467-8c48-cbdaa1f1e611",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/embeddings_dict.pkl\"\n",
    "\n",
    "with open(path, \"rb\") as f:\n",
    "    embeddings_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a42a2215-5c2e-4784-82f0-d71da4fddf55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Xenova/all-MiniLM-L6-v2', 'nomic-ai/nomic-embed-text-v1.5', 'Xenova/all-mpnet-base-v2', 'Xenova/paraphrase-mpnet-base-v2', 'Xenova/all-MiniLM-L12-v2', 'nomic-ai/modernbert-embed-base'])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a0936cdb-c75a-4dd4-8bc5-8659729c69f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"Xenova/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "# model_name = \"Xenova/distiluse-base-multilingual-cased-v1\"\n",
    "# model_name = \"Xenova/all-MiniLM-L6-v2\"\n",
    "# model_name = \"nomic-ai/nomic-embed-text-v1.5\"\n",
    "model_name = \"nomic-ai/modernbert-embed-base\"\n",
    "EMBEDDING_SIZE = embeddings_sizes[model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f36de95c-ff05-4175-8cde-8b5003f77caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = []\n",
    "for idx, vec in enumerate(embeddings_dict[model_name]):\n",
    "    items.append((idx, list(vec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8b286fac-0924-42fe-aa5b-2910311f0f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_normalized = model_name.replace(\"/\",\"_\").replace(\"-\",\"_\").replace(\".\",\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "6f8d21e2-51ba-41b0-86f0-f13178902d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.execute(f\"CREATE VIRTUAL TABLE vec_items_{model_name_normalized} USING vec0(embedding float[{EMBEDDING_SIZE}])\")\n",
    "\n",
    "with db:\n",
    "    for item in items:\n",
    "        db.execute(\n",
    "            f\"INSERT INTO vec_items_{model_name_normalized}(rowid, embedding) VALUES (?, ?)\",\n",
    "            [item[0], serialize_f32(item[1])],\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c2adb94b-e78e-43a4-a23a-905a9d72657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.read_csv(\"../data/history.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "18496f88-d953-4c44-8a89-a6d58eb40ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected model is nomic-ai/modernbert-embed-base\n"
     ]
    }
   ],
   "source": [
    "query = \"quantization\"\n",
    "\n",
    "fe = FeatureExtractor(EMBEDDING_MODELS_DICT, model_name=model_name)\n",
    "query_embedding = fe.get_embeddings([query])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "fabd843c-fa3d-48df-a7ed-3bee83e636ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "2c6c6098-5206-463d-8315-262edc5ae3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(231, 0.4183337986469269), (526, 0.45645061135292053), (16, 0.4878166913986206)]\n"
     ]
    }
   ],
   "source": [
    "# using cosine distance\n",
    "rows = db.execute(\n",
    "    f\"\"\"\n",
    "      SELECT\n",
    "        rowid,\n",
    "        vec_distance_cosine(embedding, ?) AS cosine_distance\n",
    "      FROM vec_items_{model_name_normalized}\n",
    "      ORDER BY cosine_distance\n",
    "      LIMIT 3\n",
    "    \"\"\",\n",
    "    [serialize_f32(query_embedding)],\n",
    ").fetchall()\n",
    "\n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "9df3ae87-fa0b-4528-993a-4bb8ea03ee51",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b6148508-cd63-4483-9c7f-5839e16fba50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query = quantization\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>preview_image_url</th>\n",
       "      <th>frecency</th>\n",
       "      <th>last_visit_date</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>token_count</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>https://alexgarcia.xyz/sqlite-vec/guides/binary-quant.html</td>\n",
       "      <td>Binary Quantization | sqlite-vec</td>\n",
       "      <td>A vector search SQLite extension that runs anywhere!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2024-12-09 21:29:40.745769</td>\n",
       "      <td>Binary Quantization | sqlite-vec A vector search SQLite extension that runs anywhere!</td>\n",
       "      <td>19</td>\n",
       "      <td>0.418334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>https://onnxruntime.ai/docs/performance/model-optimizations/quantization.html</td>\n",
       "      <td>Quantize ONNX models | onnxruntime</td>\n",
       "      <td>ONNX Runtime: cross-platform, high performance ML inferencing and training accelerator</td>\n",
       "      <td>https://onnxruntime.ai/images/logos/onnxruntime/ORT_icon_for_light_bg.png</td>\n",
       "      <td>94.0</td>\n",
       "      <td>2024-12-04 16:42:44.791372</td>\n",
       "      <td>Quantize ONNX models | onnxruntime ONNX Runtime: cross-platform, high performance ML inferencing and training accelerator</td>\n",
       "      <td>29</td>\n",
       "      <td>0.456451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>https://github.com/YingfanWang/PaCMAP</td>\n",
       "      <td>YingfanWang/PaCMAP: PaCMAP: Large-scale Dimension Reduction Technique Preserving Both Global and Local Structure</td>\n",
       "      <td>PaCMAP: Large-scale Dimension Reduction Technique Preserving Both Global and Local Structure - YingfanWang/PaCMAP</td>\n",
       "      <td>https://opengraph.githubassets.com/cf111310da0fdafa277a43ffcfa4a4b2d4fb16e1e9132d7963fdba8b3442f507/YingfanWang/PaCMAP</td>\n",
       "      <td>2060.0</td>\n",
       "      <td>2024-12-11 18:23:49.302624</td>\n",
       "      <td>YingfanWang/PaCMAP: PaCMAP: Large-scale Dimension Reduction Technique Preserving Both Global and Local Structure PaCMAP: Large-scale Dimension Reduction Technique Preserving Both Global and Local ...</td>\n",
       "      <td>53</td>\n",
       "      <td>0.487817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                               url  \\\n",
       "231                     https://alexgarcia.xyz/sqlite-vec/guides/binary-quant.html   \n",
       "526  https://onnxruntime.ai/docs/performance/model-optimizations/quantization.html   \n",
       "16                                           https://github.com/YingfanWang/PaCMAP   \n",
       "\n",
       "                                                                                                                title  \\\n",
       "231                                                                                  Binary Quantization | sqlite-vec   \n",
       "526                                                                                Quantize ONNX models | onnxruntime   \n",
       "16   YingfanWang/PaCMAP: PaCMAP: Large-scale Dimension Reduction Technique Preserving Both Global and Local Structure   \n",
       "\n",
       "                                                                                                           description  \\\n",
       "231                                                               A vector search SQLite extension that runs anywhere!   \n",
       "526                             ONNX Runtime: cross-platform, high performance ML inferencing and training accelerator   \n",
       "16   PaCMAP: Large-scale Dimension Reduction Technique Preserving Both Global and Local Structure - YingfanWang/PaCMAP   \n",
       "\n",
       "                                                                                                          preview_image_url  \\\n",
       "231                                                                                                                     NaN   \n",
       "526                                               https://onnxruntime.ai/images/logos/onnxruntime/ORT_icon_for_light_bg.png   \n",
       "16   https://opengraph.githubassets.com/cf111310da0fdafa277a43ffcfa4a4b2d4fb16e1e9132d7963fdba8b3442f507/YingfanWang/PaCMAP   \n",
       "\n",
       "     frecency             last_visit_date  \\\n",
       "231      98.0  2024-12-09 21:29:40.745769   \n",
       "526      94.0  2024-12-04 16:42:44.791372   \n",
       "16     2060.0  2024-12-11 18:23:49.302624   \n",
       "\n",
       "                                                                                                                                                                                               combined_text  \\\n",
       "231                                                                                                                    Binary Quantization | sqlite-vec A vector search SQLite extension that runs anywhere!   \n",
       "526                                                                                Quantize ONNX models | onnxruntime ONNX Runtime: cross-platform, high performance ML inferencing and training accelerator   \n",
       "16   YingfanWang/PaCMAP: PaCMAP: Large-scale Dimension Reduction Technique Preserving Both Global and Local Structure PaCMAP: Large-scale Dimension Reduction Technique Preserving Both Global and Local ...   \n",
       "\n",
       "     token_count  distance  \n",
       "231           19  0.418334  \n",
       "526           29  0.456451  \n",
       "16            53  0.487817  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"query = {query}\")\n",
    "# history.iloc[[row for row, score in rows]]\n",
    "row_indices = [row for row, score in rows]\n",
    "distance = [score for row, score in rows]\n",
    "\n",
    "selected_rows = history.iloc[row_indices].copy()\n",
    "selected_rows[\"distance\"] = distance\n",
    "selected_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616f7b84-a967-42ae-8a2d-3e9bdbf2075b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243ce38c-de8e-47aa-a977-8e188f19de8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
