{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48013420-7f69-4e40-8ff9-a90cd1531bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.13\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5774ac7-fdfc-4352-bb4d-55fa5f80c7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f136352-73e7-4589-bdd0-e21c0e2186e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ../models/tmp/static-retrieval-mrl-en-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84478c64-cb8f-486f-99dc-80172a29966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_embedding_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2845cbb7-c6c0-4a08-b1e0-50b6706fad6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "class WrappedModel(torch.nn.Module):\n",
    "  def __init__(self, m):\n",
    "    super().__init__()\n",
    "    self.embedding = m[0].embedding\n",
    "    \n",
    "  def forward(self, input_ids, attention_mask):\n",
    "    indices = input_ids[attention_mask == 1]\n",
    "    offsets = torch.cat([torch.tensor([0]), attention_mask.sum(dim=1)[:-1].cumsum(dim=0)])\n",
    "    return self.embedding(indices, offsets)\n",
    "\n",
    "shape = (3, 4)\n",
    "input_ids = torch.tensor([1, 2, 3, 4, 5, 6, -1, -1, 1, 1, 1, 0]).view(shape)\n",
    "attention_mask = torch.tensor([1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0]).view(shape)\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/static-retrieval-mrl-en-v1\", device=\"cpu\", truncate_dim=tgt_embedding_size)\n",
    "wrapped = WrappedModel(model) # test forward pass\n",
    "\n",
    "# # Export the model\n",
    "# torch.onnx.export(wrapped,\n",
    "#                   (input_ids, attention_mask),\n",
    "#                   \"../models/tmp/static-retrieval-mrl-en-v1/model.onnx\",\n",
    "#                   export_params=True,\n",
    "#                   opset_version=14,\n",
    "#                   do_constant_folding=True,\n",
    "#                   input_names = ['input_ids', 'attention_mask'],\n",
    "#                   output_names = ['sentence_embedding'],\n",
    "#                   dynamic_axes={\n",
    "#                       'input_ids' : {0 : 'batch_size', 1: 'sequence_length'},\n",
    "#                       'attention_mask' : {0 : 'batch_size', 1: 'sequence_length'},\n",
    "#                       'sentence_embedding' : {0 : 'batch_size'},\n",
    "#                   })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a530cb9-bf89-4b24-907b-fdc5bf831edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingBag(30522, 1024, mode='mean')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapped.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aed3f9bf-ddf8-400b-8da0-dfd20e3cc23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model[0].embedding.state_dict()['weight'].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a25edf1-7817-4c56-9607-e75b749b031a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30522, 1024)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67c7754e-9462-4439-88f7-7838f92ade03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30522, 256)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_tgt = embeddings[:,:tgt_embedding_size]\n",
    "embeddings_tgt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7122d2a3-9714-4cf2-bd05-85e9b203b1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model[0].tokenizer.get_vocab())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2379fab1-f32d-4d2e-acf4-4eabbbd0ccc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vocab = model[0].tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9125e73-5200-47ff-81bd-b79fb5905664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: goodbye, id = 9119\n",
      "Token: argues, id = 9251\n",
      "Token: 2009, id = 2268\n",
      "Token: benches, id = 19571\n",
      "Token: megan, id = 12756\n",
      "Token: ##tters, id = 24168\n",
      "Token: guillermo, id = 21070\n",
      "Token: ##erland, id = 22492\n",
      "Token: ##eous, id = 14769\n",
      "Token: â€ž, id = 1525\n",
      "Token: ##ammed, id = 27479\n"
     ]
    }
   ],
   "source": [
    "# vocab\n",
    "steps = 0\n",
    "for token, id in vocab.items():\n",
    "    print(f\"Token: {token}, id = {id}\")\n",
    "    steps += 1\n",
    "    if steps > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c7b92f9-7f5f-4875-a3d6-c3204eb532e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_sorted = dict(sorted([(token, idx) for token,idx in vocab.items()], key=lambda kv: kv[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8011393a-ed43-43ed-bd22-0ee4529b1b84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# vocab_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a5baeb2-3c7e-4e08-8778-f5d1e985bdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted([(k, v) for k,v in vocab.items()], key=lambda x: x[1])[1000:1100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68290222-8762-4c3d-85ea-c3d8715a7ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# def embed(query):\n",
    "#     input_ids = [vocab.get(word, 0) for word in query.lower().split()]\n",
    "#     return np.mean([embeddings[input_id, :tgt_embedding_size] for input_id in input_ids], axis=0)\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Initialize the tokenizer with a pre-trained BERT model.\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Your input sentence.\n",
    "# sentence = \"hello world this is a test extraordinarily the simplest\"\n",
    "\n",
    "\n",
    "def embed(query):\n",
    "    tokens = tokenizer.tokenize(query)\n",
    "    print(\"Tokens:\", tokens)\n",
    "    input_ids = [vocab.get(token, 0) for token in tokens]\n",
    "    return np.mean([embeddings[input_id, :tgt_embedding_size] for input_id in input_ids], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc1ee976-827e-4597-9f5e-765494386169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['fun', 'filled', 'morning', 'at', 'school']\n",
      "Tokens: ['bus', 'departing', 'time']\n",
      "Tokens: ['it', 'was', 'an', 'action', 'movie']\n",
      "Tokens: ['cs', 'algorithms']\n",
      "Tokens: ['basketball', 'player']\n",
      "Tokens: ['diabetes', 'treatment']\n",
      "Tokens: ['hello', 'world', 'this', 'is', 'a', 'test', 'extra', '##ord', '##ina', '##rily', 'the', 'simplest']\n"
     ]
    }
   ],
   "source": [
    "# query = \"fun filled morning at school\"\n",
    "# query = \"bus departing time\"\n",
    "# query = \"it was an action movie\"\n",
    "# query = \"cs algorithms\"\n",
    "# query = \"basketball player\"\n",
    "query = \"diabetes treatment\"\n",
    "# query = \"hello world this is a test extra ##ord ##ina ##rily the simplest\"\n",
    "\n",
    "# e1 = embed(query)\n",
    "\n",
    "queries = [\n",
    "    \"fun filled morning at school\",\n",
    "    \"bus departing time\",\n",
    "    \"it was an action movie\",\n",
    "    \"cs algorithms\",\n",
    "    \"basketball player\",\n",
    "    \"diabetes treatment\",\n",
    "    \"hello world this is a test extraordinarily the simplest\"\n",
    "]\n",
    "\n",
    "e1 = np.array([embed(query) for query in queries])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4675a8f-eb4a-49cf-96e0-2df33cefee48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.879415 ,  1.8830419,  1.8674997,  1.0040632,  4.127914 ,\n",
       "       -2.4525557,  0.5300663,  0.842521 ,  5.7000585,  8.80159  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1[6, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db2f89ce-4912-4b83-84b1-f75eea50ce25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 256)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6d58897-4e62-4534-b9b7-f2b8527d8a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "e1_from_transformers = model.encode(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7e0f344-3184-4787-b374-b03793acdb59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 256)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1_from_transformers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d31bc7d0-133b-42cd-8ecc-145e6811ce61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.879415 ,  1.8830419,  1.8674997,  1.0040632,  4.127914 ,\n",
       "       -2.4525557,  0.5300663,  0.842521 ,  5.7000585,  8.80159  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1_from_transformers[6, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8519a002-bb87-4d2b-bd10-0bd10a4a1201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1.shape == e1_from_transformers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53df932b-5427-441a-ab86-ed94f7355fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "198b9f11-2591-45de-9a74-3feb58fb9f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all([all(e1[i] == e1_from_transformers[i]) for i in range(e1.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0984ea3-b24c-488a-894b-a855731232e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all(e1 == e1_from_transformers)\n",
    "all([all(e1[i] == e1_from_transformers[i]) for i in range(e1.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cea93bd9-26e5-41f2-b118-d7cc56c5c93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30522, 256)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_tgt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6451605-1c36-4d98-ad71-998745f8f727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8.065368  ,  -8.882175  , -20.208576  , -18.220303  ,\n",
       "         0.26347125,   2.1979225 ,  19.462276  ,  -1.8650678 ,\n",
       "        11.297153  , -10.203839  ], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_tgt[vocab['##ord'], :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9cbb8db6-f65f-4975-8ac9-31b83fc4a3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"School is kind to students\",\n",
    "    \"lovely day and wonderful weather\",\n",
    "    \"nearest pharmacy\",\n",
    "    \"lebran james\",\n",
    "    \"train schedule\",\n",
    "    \"hollywood flick\",\n",
    "    \"computers\",\n",
    "    \"soccer is nice to watch\",\n",
    "    \"insulin research\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3697f296-4a70-408f-a176-25cfa5a7d8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['school', 'is', 'kind', 'to', 'students']\n",
      "Tokens: ['lovely', 'day', 'and', 'wonderful', 'weather']\n",
      "Tokens: ['nearest', 'pharmacy']\n",
      "Tokens: ['le', '##bra', '##n', 'james']\n",
      "Tokens: ['train', 'schedule']\n",
      "Tokens: ['hollywood', 'flick']\n",
      "Tokens: ['computers']\n",
      "Tokens: ['soccer', 'is', 'nice', 'to', 'watch']\n",
      "Tokens: ['insulin', 'research']\n"
     ]
    }
   ],
   "source": [
    "corpus_embeddings = [embed(text) for text in corpus]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "882aac7d-e90b-4c7c-a22d-31e805045902",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cosine_similarity(query_embedding: list[float], corpus_embeddings: list[list[float]]) -> np.ndarray:\n",
    "    # Convert lists to numpy arrays\n",
    "    query = np.array(query_embedding)\n",
    "    corpus = np.array(corpus_embeddings)\n",
    "    \n",
    "    # Normalize query and corpus vectors\n",
    "    query_norm = query / np.linalg.norm(query)\n",
    "    corpus_norm = corpus / np.linalg.norm(corpus, axis=1, keepdims=True)\n",
    "    \n",
    "    # Compute cosine similarity (dot product of normalized vectors)\n",
    "    similarities = corpus_norm.dot(query_norm)\n",
    "    print(similarities)\n",
    "    return np.argmax(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b378937c-f551-469e-bdb0-809293ae5d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 256)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb364030-ee11-4c74-9023-afab88f38192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query = diabetes treatment\n",
      "[-0.1352294  -0.04187926  0.08710091  0.00459079 -0.11412142 -0.02789718\n",
      " -0.00536665  0.04453617  0.39935726]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'insulin research'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similar_idx = cosine_similarity(e1, corpus_embeddings).item()\n",
    "print(f\"query = {queries[5]}\")\n",
    "similar_idx = cosine_similarity(e1[5], corpus_embeddings).item()\n",
    "corpus[similar_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "16da2fda-43be-47b8-9871-0218c2016b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = model[0].tokenize([\"hello world and the earthly\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb77357b-12ab-4d6b-be07-58cfb4bcbe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7bb286-22f0-4c4e-83a2-a070912d4706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db72328f-e6e6-46bd-8eba-ca943c60a061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# np.mean([embeddings[input_id.item(), :tgt_embedding_size] for input_id in inputs['input_ids']], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5707f070-3119-49eb-bbae-2d75982163fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # vocab_sorted\n",
    "# list(vocab_sorted.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c711bdd-1d56-443f-8553-d856673dadba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import numpy as np\n",
    "\n",
    "def save_embeddings(filename, vocab, embeddings):\n",
    "    # vocab: list of strings (words)\n",
    "    # embeddings: NumPy array of shape (vocab_size, embedding_dim), dtype=np.float32\n",
    "    vocab_size, embedding_dim = embeddings.shape\n",
    "\n",
    "    with open(filename, \"wb\") as f:\n",
    "        # Write a header: magic number \"EMBD\", vocab_size, and embedding_dim (unsigned ints)\n",
    "        f.write(b\"EMBD\")\n",
    "        f.write(struct.pack(\"<II\", vocab_size, embedding_dim))\n",
    "        \n",
    "        # Write each word: first its length then the word bytes\n",
    "        for word in vocab:\n",
    "            encoded = word.encode(\"utf-8\")\n",
    "            f.write(struct.pack(\"<I\", len(encoded)))\n",
    "            f.write(encoded)\n",
    "        \n",
    "        # Write the embedding matrix as contiguous block of little-endian floats\n",
    "        f.write(embeddings.astype(np.float32).tobytes())\n",
    "\n",
    "# Example usage:\n",
    "# vocab = [\"hello\", \"world\", \"foo\", \"bar\"]\n",
    "# embeddings = np.random.rand(len(vocab), 300).astype(np.float32)\n",
    "save_embeddings(f\"embeddings_dim_{tgt_embedding_size}.bin\", list(vocab_sorted.keys()), embeddings_tgt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e01e5e3-1c40-4cae-a389-d29e9d290ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_tgt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bcf599-4839-4a86-94b3-d9aca30a7a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diabetes treatment\n",
    "vocab[\"treatment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8328fd2f-8c4c-4b13-8a2b-91f57469e342",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_tgt[3949, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885cca38-856b-4688-ba80-c784d76cb715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16106927-c1df-4126-af3c-8382c0c386c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !huggingface-cli whoami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c806fb84-b1ab-4430-ab81-586cbdf1436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi, HfFolder, Repository\n",
    "\n",
    "model_id = \"Mozilla/static-retrieval-mrl-en-v1\"\n",
    "bin_file_path = f\"embeddings_dim_{tgt_embedding_size}.bin\"\n",
    "target_path_in_repo = f\"embeddings_dim_{tgt_embedding_size}.bin\"\n",
    "print(f\"target_path_in_repo = {target_path_in_repo}\")\n",
    "\n",
    "api = HfApi()\n",
    "api.upload_file(\n",
    "    path_or_fileobj=bin_file_path,\n",
    "    path_in_repo=target_path_in_repo,\n",
    "    repo_id=model_id,\n",
    "    repo_type=\"model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa22a6a-2120-455d-8eef-ae30741130da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e943136f-433a-4a1b-af39-f67fc2e3b27a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
